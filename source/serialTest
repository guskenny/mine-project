#!/bin/bash
# Usage: sbatch slurm-serial-job-script
# Prepared By: Kai Xi,  Oct 2014
#              help@massive.org.au

# NOTE: To activate a SLURM option, remove the whitespace between the '#' and 'SBATCH'

# To give your job a name, replace "MyJob" with an appropriate name
# SBATCH --job-name=MyJob


# To set a project account for credit charging, 
# SBATCH --account=pmosp


# Request CPU resource for a serial job
# SBATCH --ntasks=1
# SBATCH --ntasks-per-node=1
# SBATCH --cpus-per-task=1

# Memory usage (MB)
#SBATCH --mem-per-cpu=55000

# Set your minimum acceptable walltime, format: day-hours:minutes:seconds
#SBATCH --time=0-12:00:00


# To receive an email when job completes or fails
#SBATCH --mail-user=gus.kenny@monash.edu
#SBATCH --mail-type=END
# SBATCH --mail-type=FAIL


# Set the file for output (stdout)
#SBATCH --output=.MyJob-%j.out

# Set the file for error log (stderr)
# SBATCH --error=MyJob-%j.err


# Use reserved node to run job when a node reservation is made for you already
# SBATCH --reservation=reservation_name


# Command to run a serial job
# srun ./max_closure < test.dat
# srun ./max_closure < test3.dat
# srun ./max_closure < test2.dat
# srun ./max_closure < test4.dat
# srun ./max_closure < test5.dat
srun ./QOLpcpsp -c -B Data/zuck_med
